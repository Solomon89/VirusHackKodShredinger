<!DOCTYPE html>
<!-- saved from url=(0049)https://docs.opencv.org/3.4/js_video_display.html -->
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Video Capture Example</title>
    
</head>
<body>
    <div class="form-inline btnAllert">
        <a href="" id="booring" class="btn btn-success"><img src="~/img/cil_lightbulb.png" alt="Alternate Text" /></a>
        <a href="" id="understand" class="btn btn-success"><img src="~/img/cil_mood-good.png" alt="Alternate Text" /></a>
    </div>
    <p class="err" id="errorMessage"></p>
    <div>
        <table cellpadding="0" cellspacing="0" width="0" border="0">
            <tbody>
                <tr>
                    <td>
                        <video id="videoInput" width="50" height="50" data-video="0"></video>
                    </td>
                    <td>
                        <canvas id="canvasOutput" width="50" height="50"></canvas>
                    </td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>
    </div>

    <script src="~/js/adapter-5.0.4.js" type="text/javascript"></script>
    <script src="~/js/utils.js" type="text/javascript"></script>
    <script id="codeSnippet" type="text/code-snippet">

    </script>
    <script type="text/javascript">
        let utils = new Utils('errorMessage');

        utils.loadCode('codeSnippet', 'codeEditor');

        let streaming = false;
        let videoInput = document.getElementById('videoInput');
        let startAndStop = document.getElementById('startAndStop');
        let canvasOutput = document.getElementById('canvasOutput');
        let canvasContext = canvasOutput.getContext('2d');

        startAndStop.addEventListener('click', () => {
            if (!streaming) {
                utils.clearError();
                utils.startCamera('qvga', onVideoStarted, 'videoInput');
            } else {
                utils.stopCamera();
                onVideoStopped();
            }
        });

        function onVideoStarted() {
            streaming = true;
            startAndStop.innerText = 'Stop';
            videoInput.width = videoInput.videoWidth;
            videoInput.height = videoInput.videoHeight;
            startRecognation();
        }
        function startRecognation() {

            let video = document.getElementById('videoInput');
            let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let gray = new cv.Mat();
            let cap = new cv.VideoCapture(video);
            let faces = new cv.RectVector();
            let eyes = new cv.RectVector();
            let classifier = new cv.CascadeClassifier();
            let eyeCascade = new cv.CascadeClassifier();
            // load pre-trained classifiers
            classifier.load('haarcascade_frontalface_default.xml');
            eyeCascade.load('haarcascade_eye.xml');
            let EyeEventX = new Array();
            let EyeEventY = new Array();
            let current = 0;

            const FPS = 30;
            function processVideo() {
                try {
                    if (!streaming) {
                        // clean and stop.
                        src.delete();
                        dst.delete();
                        gray.delete();
                        faces.delete();
                        classifier.delete();
                        return;
                    }
                    let begin = Date.now();

                    // start processing.
                    cap.read(src);
                    src.copyTo(dst);
                    cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
                    // detect faces.
                    classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                    // draw faces.
                    for (let i = 0; i < faces.size(); ++i) {
                        let face = faces.get(i);
                        let roiGray = gray.roi(faces.get(i));
                        let roiSrc = src.roi(faces.get(i));
                        let point1 = new cv.Point(face.x, face.y);
                        let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                        cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
                        eyeCascade.detectMultiScale(roiGray, eyes);
                        for (let j = 0; j < eyes.size(); ++j) {
                            let point1Y = new cv.Point(point1.x + eyes.get(j).x, point1.y + eyes.get(j).y);
                            let point2Y = new cv.Point(point1.x + eyes.get(j).x + eyes.get(j).width,
                                point1.y + eyes.get(j).y + eyes.get(j).height);
                            cv.rectangle(dst, point1Y, point2Y, [0, 0, 255, 255]);
                            //cv.circle(dst, (point1.x + eyes.get(j).x + (eyes.get(j).width / 2), point1.y + eyes.get(j).y + (eyes.get(j).height / 2)), 10, (0, 0, 255), -1);
                            let center = new cv.Point(point1.x + eyes.get(j).x + (eyes.get(j).width / 2), point1.y + eyes.get(j).y + (eyes.get(j).height / 2));
                            let circleColor = new cv.Scalar(255, 153, 102);
                            cv.circle(dst, center, 1, circleColor);

                            
                        }
                        if (i == 0) {
                            EyeEventX.push(Math.round(point1.x + (face.width / 2)));
                            EyeEventY.push(Math.round(point1.y + (face.height / 2)));
                            current++;
                            if (current == 100) {
                                let sdvY = standardDeviation(EyeEventY);
                                let sdvX = standardDeviation(EyeEventX);
                                showInfo(sdvY, sdvX);
                                console.log("X:SD:" + standardDeviation(EyeEventX) + " AVG:" + average(EyeEventX));
                                console.log("Y:SD:" + standardDeviation(EyeEventY) + " AVG:" + average(EyeEventY));
                                current = 0;
                                EyeEventX = new Array();
                                EyeEventY = new Array();
                            }
                        }
                    }
                    cv.imshow('canvasOutput', dst);
                    // schedule the next one.
                    let delay = 1000 / FPS - (Date.now() - begin);
                    setTimeout(processVideo, delay);
                } catch (err) {
                    utils.printError(err);
                }
            };

            // schedule the first one.
            setTimeout(processVideo, 0);
        }
        function showInfo(stdY, stdX) {
            if (stdY < 10) {
                $("#booring").addClass('btn-success')
                $("#booring").removeClass('btn-danger')
            }
            else {
                $("#booring").removeClass('btn-success')
                $("#booring").addClass('btn-danger')
            }
            if (stdX < 15) {
                $("#understand").addClass('btn-success')
                $("#understand").removeClass('btn-danger')
            }
            else {
                $("#understand").removeClass('btn-success')
                $("#understand").addClass('btn-danger')
            }
        }
        function standardDeviation(values) {
            var avg = average(values);

            var squareDiffs = values.map(function (value) {
                var diff = value - avg;
                var sqrDiff = diff * diff;
                return sqrDiff;
            });

            var avgSquareDiff = average(squareDiffs);

            var stdDev = Math.sqrt(avgSquareDiff);
            return stdDev;
        }

        function average(data) {
            var sum = data.reduce(function (sum, value) {
                return sum + value;
            }, 0);

            var avg = sum / data.length;
            return avg;
        }
        function onVideoStopped() {
            streaming = false;
            canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
            startAndStop.innerText = 'Start';
        }
        
        utils.loadOpenCv(() => {
            let faceCascadeFile = '../haarcascade_frontalface_default.xml';
            utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
                startAndStop.removeAttribute('disabled');
            });
            let faceCascadeEye = '../haarcascade_eye.xml';

            utils.createFileFromUrl(faceCascadeEye, faceCascadeEye, () => {
                startAndStop.removeAttribute('disabled');
            });
            utils.startCamera('qvga', onVideoStarted, 'videoInput');
        });

    </script>


    <div at-magnifier-wrapper=""><div class="at-theme-light"><div class="at-base notranslate" translate="no"><div class="Z1-AJ" style="top: 0px; left: 0px;"></div></div></div></div>
</body>
</html>